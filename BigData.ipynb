{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTi8E-_jK9jr",
        "outputId": "c998f68a-ae4b-4058-cf19-a819a0da278f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172.28.0.12 \n",
            "34.82.41.67/bin/bash: line 1:  grep LISTEN: command not found\n",
            "lsof: illegal option character: �\n",
            "lsof: illegal option character: �\n",
            "lsof 4.93.2\n",
            " latest revision: https://github.com/lsof-org/lsof\n",
            " latest FAQ: https://github.com/lsof-org/lsof/blob/master/00FAQ\n",
            " latest (non-formatted) man page: https://github.com/lsof-org/lsof/blob/master/Lsof.8\n",
            " usage: [-?abhKlnNoOPRtUvVX] [+|-c c] [+|-d s] [+D D] [+|-E] [+|-e s] [+|-f[gG]]\n",
            " [-F [f]] [-g [s]] [-i [i]] [+|-L [l]] [+m [m]] [+|-M] [-o [o]] [-p s]\n",
            " [+|-r [t]] [-s [p:s]] [-S [t]] [-T [t]] [-u s] [+|-w] [-x [fl]] [--] [names]\n",
            "Use the ``-h'' option to get more help information.\n"
          ]
        }
      ],
      "source": [
        "!hostname -I\n",
        "\n",
        "#gives ip address\n",
        "!curl ipecho.net/plain\n",
        "\n",
        "#Gives ip addresses with port numbers\n",
        "!sudo lsof -i -P -n | grep LISTEN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install confluent_kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HC4pXIDLS1f",
        "outputId": "62c42cf6-c4bc-489e-c375-90806f823a05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: confluent_kafka in /usr/local/lib/python3.10/dist-packages (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import requests\n",
        "\n",
        "def delivery_report(err, msg):\n",
        "    if err is not None:\n",
        "        print('Message delivery failed: {}'.format(err))\n",
        "    else:\n",
        "        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
        "\n",
        "def fetch_data_and_send_to_kafka(url):\n",
        "    # Confluent Kafka Producer ayarları\n",
        "    producer_conf = {\n",
        "        'bootstrap.servers': 'pkc-12576z.us-west2.gcp.confluent.cloud:9092',\n",
        "        'security.protocol': 'SASL_SSL',\n",
        "        'sasl.mechanism': 'PLAIN',\n",
        "        'sasl.username': 'KBET22XVE7ORVE46',\n",
        "        'sasl.password': 'YUzpQqFx92/zZ10TlNbAK7RR1Zgo61xs6++GGornSuisj0dWspqAIcPr8DsUFquV'\n",
        "    }\n",
        "\n",
        "    # Producer oluşturma\n",
        "    producer = Producer(producer_conf)\n",
        "    topic = 'Mehmet'\n",
        "\n",
        "    # URL'den veri çekme\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.text\n",
        "        # URL'yi key olarak kullanarak veriyi Kafka'ya gönderme\n",
        "        producer.produce(topic, key=url.encode('utf-8'), value=data.encode('utf-8'), callback=delivery_report)\n",
        "        producer.flush()\n",
        "        print(\"Success: Data sent to Kafka\")\n",
        "    else:\n",
        "        print(f\"Error: Failed to fetch data from URL. Status code: {response.status_code}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    url = input(\"Enter URL: \")\n",
        "    fetch_data_and_send_to_kafka(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyYmtEg-Lggx",
        "outputId": "652cb21a-c3ca-4ea2-9c6e-86264819f641"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter URL: https://www.cnnturk.com/dunya/galeri/blinken-bir-sok-daha-beni-degil-onu-tutuklamaniz-gerekiyor-2116791\n",
            "Message delivered to Mehmet [5]\n",
            "Success: Data sent to Kafka\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install confluent_kafka pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyvLMo-YLo5W",
        "outputId": "84c4b558-0d01-4877-c287-82e14cafadc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: confluent_kafka in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.7.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer, KafkaException, KafkaError\n",
        "from pymongo import MongoClient\n",
        "\n",
        "def insert_data_to_mongo(url, data, collection):\n",
        "    result = collection.insert_one({\"url\": url, \"data\": data, \"state\": 0,\"category\":None})\n",
        "    if result.inserted_id:\n",
        "        print(f\"Data inserted with ID: {result.inserted_id}\")\n",
        "    else:\n",
        "        print(\"Failed to insert data\")\n",
        "\n",
        "def kafka_consumer_example():\n",
        "    # Confluent Kafka Consumer ayarları\n",
        "    consumer_conf = {\n",
        "        'bootstrap.servers': 'pkc-12576z.us-west2.gcp.confluent.cloud:9092',\n",
        "        'security.protocol': 'SASL_SSL',\n",
        "        'sasl.mechanism': 'PLAIN',\n",
        "        'sasl.username': 'KBET22XVE7ORVE46',\n",
        "        'sasl.password': 'YUzpQqFx92/zZ10TlNbAK7RR1Zgo61xs6++GGornSuisj0dWspqAIcPr8DsUFquV',\n",
        "        'group.id': 'my_group',\n",
        "        'auto.offset.reset': 'earliest'\n",
        "    }\n",
        "\n",
        "    # Consumer oluşturma\n",
        "    consumer = Consumer(consumer_conf)\n",
        "    topic = 'Mehmet'\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "    # MongoDB bağlantısını oluşturma\n",
        "    client = MongoClient(\"mongodb+srv://mehmet34:mehmet175e@atlascluster.j3z8vqq.mongodb.net/\")\n",
        "    db = client['mydatabase']\n",
        "    collection = db['mycollection61']\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            msg = consumer.poll(timeout=1.0)\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                    print(f\"End of partition reached {msg.topic()}/{msg.partition()}\")\n",
        "                else:\n",
        "                    raise KafkaException(msg.error())\n",
        "            else:\n",
        "                url = msg.key().decode('utf-8') if msg.key() is not None else None\n",
        "                data = msg.value().decode('utf-8')\n",
        "                insert_data_to_mongo(url, data, collection)\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    finally:\n",
        "        # Clean up\n",
        "        consumer.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    kafka_consumer_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWSzZI8rLqoT",
        "outputId": "824a1ed2-9790-4ff7-9e02-e49294ab5769"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inserted with ID: 664e7437085085c26a3eccd7\n",
            "Data inserted with ID: 664e7438085085c26a3eccd8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "!pip install certifi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3STOWU4eMEpb",
        "outputId": "2b8a5f9e-3de5-43f7-d68c-b6bbad14b0d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.7.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from pymongo.errors import ServerSelectionTimeoutError\n",
        "import certifi\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "try:\n",
        "    client = MongoClient(\n",
        "        \"mongodb+srv://mehmet34:mehmet175e@atlascluster.j3z8vqq.mongodb.net/\",\n",
        "        tlsCAFile=certifi.where()\n",
        "    )\n",
        "    db = client[\"mydatabase\"]\n",
        "    collection = db[\"mycollection61\"]\n",
        "\n",
        "    # İşlenmemiş verileri al\n",
        "    documents = collection.find({\"data\": {\"$exists\": True}, \"state\": 0})\n",
        "\n",
        "    # İşlenmemiş veri yoksa mesaj ver\n",
        "    if collection.count_documents({\"data\": {\"$exists\": True}, \"state\": 0}) == 0:\n",
        "        print(\"İşlenmemiş veri yok.\")\n",
        "    else:\n",
        "        for document in documents:\n",
        "            text = document['data']\n",
        "            soup = BeautifulSoup(text, 'html.parser')\n",
        "\n",
        "            #etiketleri temizle\n",
        "            for a_tag in soup.find_all(\"a\"):\n",
        "                a_tag.decompose()\n",
        "            for img_tag in soup.find_all(\"img\"):\n",
        "                img_tag.decompose()\n",
        "            for s_tag in soup.find_all(\"strong\"):\n",
        "                s_tag.decompose()\n",
        "\n",
        "            # Article etiketlerini bul ve işle\n",
        "            articles = soup.find_all(\"article\")\n",
        "            print(document['url'])\n",
        "            print(\"\\n\")\n",
        "\n",
        "            if not articles:\n",
        "                print(f\"Uyarı: {document['url']} adresinde article etiketi bulunamadı.\")\n",
        "                continue  # Eğer article etiketi yoksa bu dokümanı atla\n",
        "\n",
        "            text_sum_list = []\n",
        "            for article in articles:\n",
        "                paragraphs = article.find_all([\"p\", \"h1\", \"h2\"])\n",
        "                combined_text = \" \".join(element.get_text() for element in paragraphs)\n",
        "            #    text_sum = combined_text.strip().split()\n",
        "             #   text_sum_list.extend(text_sum)\n",
        "\n",
        "            query = {\"_id\": document[\"_id\"]}\n",
        "            new_data = {\"$set\": {\"data\": combined_text, \"state\": 1}}\n",
        "\n",
        "            try:\n",
        "                collection.update_one(query, new_data)\n",
        "                print(\"Veri başarıyla Ayrıştırıldı.\")\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "            print(\"#########\")\n",
        "\n",
        "except ServerSelectionTimeoutError as err:\n",
        "    print(\"MongoDB bağlantı hatası:\", err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "381ZTfGdL0j1",
        "outputId": "0de2880e-be3d-43b2-e811-6ed597de493f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.cnnturk.com/dunya/galeri/blinken-bir-sok-daha-beni-degil-onu-tutuklamaniz-gerekiyor-2116791\n",
            "\n",
            "\n",
            "Veri başarıyla Ayrıştırıldı.\n",
            "#########\n",
            "https://onedio.com/haber/bir-torpil-iddiasi-daha-gelir-mi-kizilcik-serbeti-nilay-in-kardesi-sandik-kokusu-ndan-cikti-1224256\n",
            "\n",
            "\n",
            "Veri başarıyla Ayrıştırıldı.\n",
            "#########\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install pandas xlrd\n",
        "!pip install gspread pandas gspread_dataframe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6kuLf11Mrcv",
        "outputId": "1e823ab5-62d0-4d5f-a018-2e60466b994e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from gspread) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from gspread) (1.2.0)\n",
            "Requirement already satisfied: StrEnum==0.4.15 in /usr/local/lib/python3.10/dist-packages (from gspread) (0.4.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from gspread_dataframe) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "import certifi\n",
        "import bs4\n",
        "import numpy as np\n",
        "\n",
        "file_path = '/content/news.xls'\n",
        "\n",
        "\n",
        "# Excel dosyası xls\n",
        "veri = pd.read_excel(file_path, engine='xlrd')\n",
        "veri = veri[~veri['category'].isin(['dünya', 'genel','güncel','planet','türkiye'])]\n",
        "bos_degerler = veri['content'].isnull() | veri['content'].str.strip().eq('')\n",
        "veri = veri[~bos_degerler]\n",
        "\n",
        "#'Content' ve 'Headline' sütunlarını birleştir\n",
        "veri['content_headline'] = veri['content'].astype(str) + \" \" + veri['headline'].astype(str)\n",
        "\n",
        "\n",
        "# Özellikler ve etiketler\n",
        "X = veri['content_headline']\n",
        "y = veri['category']\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LabelEncoder oluştur\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# y'yi sayısal değerlere dönüştür\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# y'nin boyutlarını ve örneklerini kontrol edelim\n",
        "print(y.shape)\n",
        "print(y[:10])\n",
        "print(\"--\"*10)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF vektörizeri kullanarak metin verisini sayısallaştırma\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# X'in boyutlarını kontrol edelim\n",
        "print(X.shape)\n",
        "print(\"--\"*10)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Veri setlerini ayır\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ayrılan setlerin boyutlarını kontrol edelim\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Farklı k değerlerini deneyelim\n",
        "k_values = [3, 5, 7, 9]\n",
        "\n",
        "for k in k_values:\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(X_train, y_train)\n",
        "    y_pred = knn_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"k={k} için test seti doğruluk oranı: {accuracy}\")\n",
        "\n",
        "\n",
        "try:\n",
        "    client = MongoClient(\n",
        "        \"mongodb+srv://mehmet34:mehmet175e@atlascluster.j3z8vqq.mongodb.net/\",\n",
        "        tlsCAFile=certifi.where()\n",
        "    )\n",
        "    db = client[\"mydatabase\"]\n",
        "    collection = db[\"mycollection61\"]\n",
        "\n",
        "\n",
        "    documents = collection.find({\"data\": {\"$exists\": True}, \"category\": None,\"state\":1})\n",
        "\n",
        "\n",
        "    if collection.count_documents({\"data\": {\"$exists\": True}, \"state\": 1,\"category\":None}) == 0:\n",
        "        print(\"Kategorize edilmemiş veri yok.\")\n",
        "    else:\n",
        "        for document in documents:\n",
        "            text = document['data']\n",
        "\n",
        "            girdi_metni = text\n",
        "            girdi_vetörü = tfidf_vectorizer.transform([girdi_metni])  # TF-IDF vektörizasyonu ile dönüştürme\n",
        "\n",
        "      # Model tahmini\n",
        "            tahmin = knn_model.predict(girdi_vetörü)\n",
        "\n",
        "       # Tahmin sonucunu kategorik etikete dönüştürme\n",
        "            tahmin_kategori = label_encoder.inverse_transform(tahmin)\n",
        "\n",
        "        # Sonucu yazdırma\n",
        "            print(\"Girdi Metni:\", girdi_metni)\n",
        "            print(\"Tahmin Edilen Kategori:\", tahmin_kategori)\n",
        "            numpy_dizi = np.array(tahmin_kategori, dtype=object)\n",
        "           # Numpy dizisinin metin içeriğini al\n",
        "            category = numpy_dizi[0]\n",
        "            query = {\"_id\": document[\"_id\"]}\n",
        "            new_category = {\"$set\": {\"category\":category}}\n",
        "\n",
        "            try:\n",
        "                collection.update_one(query, new_category)\n",
        "                print(\"Veri Başarı İle Sınıflandırıldı.\")\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "            print(\"#########\")\n",
        "except Exception as e:\n",
        "    print(f\"Bir hata oluştu: {e}\")\n",
        "\n",
        "finally:\n",
        "    client.close()\n",
        "    print(\"MongoDB bağlantısı kapatıldı.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PKwibfBMeNQ",
        "outputId": "dab33883-d844-4d36-c5f5-982dcea6a095"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20183,)\n",
            "[0 0 0 0 0 0 0 0 0 0]\n",
            "--------------------\n",
            "(20183, 61555)\n",
            "--------------------\n",
            "(16146, 61555) (4037, 61555)\n",
            "(16146,) (4037,)\n",
            "k=3 için test seti doğruluk oranı: 0.8516224919494674\n",
            "k=5 için test seti doğruluk oranı: 0.8573197919246965\n",
            "k=7 için test seti doğruluk oranı: 0.8540995788952193\n",
            "k=9 için test seti doğruluk oranı: 0.8503839484765915\n",
            "Girdi Metni: Blinken'a bir şok daha! \"Beni değil onu tutuklamanız gerekiyor\" ABD Dışişleri Bakanı Antony Blinken, Temsilciler Meclisi Tahsisatlar Komitesinin Dış Operasyonlar ve İlgili Programlar Alt Komitesi’nde Dışişleri Bakanlığı’nın bütçe talebi konusunda verdiği ifade sırada Filistin destekçisi bir göstericinin protestosuyla karşılaştı. Protestocu, “Blinken’i tutuklamanız gerekiyor, beni değil” diye bağırdı.\n",
            "Tahmin Edilen Kategori: ['siyaset']\n",
            "Veri Başarı İle Sınıflandırıldı.\n",
            "#########\n",
            "Girdi Metni: \n",
            "Tahmin Edilen Kategori: ['ekonomi']\n",
            "Veri Başarı İle Sınıflandırıldı.\n",
            "#########\n",
            "MongoDB bağlantısı kapatıldı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTuDW2F7Msxk",
        "outputId": "93c8ee89-03a4-45d9-d6a7-da8e54cb4549"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=168c5c107ca6c4759b8b582115fe33ec15c5f3a907008b3a2b62bf4c37dac525\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pymongo import MongoClient\n",
        "from pymongo.errors import ServerSelectionTimeoutError\n",
        "import certifi\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    # MongoDB bağlantısı\n",
        "    client = MongoClient(\n",
        "        \"mongodb+srv://mehmet34:mehmet175e@atlascluster.j3z8vqq.mongodb.net/\",\n",
        "        tlsCAFile=certifi.where()\n",
        "    )\n",
        "    db = client[\"mydatabase\"]\n",
        "    collection = db[\"mycollection61\"]\n",
        "\n",
        "    # MongoDB verisini çekme\n",
        "    mongo_data = list(collection.find({\"state\": 1, \"category\": {\"$ne\": None}}, {\"url\": 1, \"data\": 1, \"category\": 1, \"_id\": 0}))\n",
        "\n",
        "    # SparkSession oluşturma\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"Spark DataFrame\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    # Pandas DataFrame oluşturma\n",
        "    pdf = pd.DataFrame(mongo_data)\n",
        "\n",
        "    # Pandas DataFrame'i Spark DataFrame'e dönüştürme\n",
        "    df = spark.createDataFrame(pdf)\n",
        "\n",
        "    # DataFrame'i gösterme\n",
        "    df.show()\n",
        "\n",
        "    #aynı tablo\n",
        "    # DataFrame'i SQL tablosu olarak kullanmak için bir geçici tablo oluşturma\n",
        "   # df.createOrReplaceTempView(\"mongo_table\")\n",
        "    #result = spark.sql(\"SELECT * FROM mongo_table WHERE category IS NOT NULL\")\n",
        "    #result.show()\n",
        "\n",
        "\n",
        "\n",
        "except ServerSelectionTimeoutError as err:\n",
        "    print(\"MongoDB bağlantı hatası:\", err)\n",
        "except Exception as e:\n",
        "    print(f\"Bir Hata Oluştu: {e}\")\n",
        "finally:\n",
        "    spark.stop()\n",
        "    client.close()\n",
        "    print(\"MongoDB bağlantısı kapatıldı.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfQcct8-Ovnh",
        "outputId": "845c8d33-5bbe-420e-c2c1-29c3887578d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------+\n",
            "|                 url|                data|category|\n",
            "+--------------------+--------------------+--------+\n",
            "|https://www.cnntu...|Göçmen mezarlığı ...|  güncel|\n",
            "|https://www.cnntu...|Blinken'a Senato'...| siyaset|\n",
            "|https://www.cnntu...|MİT Başkanı Kalın...|    spor|\n",
            "+--------------------+--------------------+--------+\n",
            "\n",
            "+--------------------+--------------------+--------+\n",
            "|                 url|                data|category|\n",
            "+--------------------+--------------------+--------+\n",
            "|https://www.cnntu...|Göçmen mezarlığı ...|  güncel|\n",
            "|https://www.cnntu...|Blinken'a Senato'...| siyaset|\n",
            "|https://www.cnntu...|MİT Başkanı Kalın...|    spor|\n",
            "+--------------------+--------------------+--------+\n",
            "\n",
            "MongoDB bağlantısı kapatıldı.\n"
          ]
        }
      ]
    }
  ]
}